{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFStream: a Flexible Network Data Analysis Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**nfstream**][repo] is a Python package providing fast, flexible, and expressive data structures designed to make working with **online** or **offline** network data both easy and intuitive. It aims to be the fundamental high-level building block for\n",
    "doing practical, **real world** network data analysis in Python. Additionally, it has\n",
    "the broader goal of becoming **a common network data processing framework for researchers** providing data reproducibility across experiments.\n",
    "\n",
    "* **Performance:** **nfstream** is designed to be fast (x10 faster with pypy3 support) with a small CPU and memory footprint.\n",
    "* **Layer-7 visibility:** **nfstream** deep packet inspection engine is based on [**nDPI**][ndpi]. It allows nfstream to perform [**reliable**][reliable] encrypted applications identification and metadata extraction (e.g. TLS, QUIC, TOR, HTTP, SSH, DNS, etc.).\n",
    "* **Flexibility:** add a flow feature in 2 lines as an [**NFPlugin**][nfplugin].\n",
    "* **Machine Learning oriented:** add your trained model as an [**NFPlugin**][nfplugin].\n",
    "\n",
    "In this notebook, we demonstrate a subset of features provided by [**nfstream**][repo].\n",
    "\n",
    "[documentation]: https://nfstream.github.io/\n",
    "[ndpi]: https://github.com/ntop/nDPI\n",
    "[nfplugin]: https://nfstream.github.io/docs/api#nfplugin\n",
    "[reliable]: http://people.ac.upc.edu/pbarlet/papers/ground-truth.pam2014.pdf\n",
    "[repo]: https://nfstream.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfstream import NFStreamer, NFPlugin\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow aggregation made simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we are going to use the main object provided by nfstream, `NFStreamer` which have the following parameters:\n",
    "\n",
    "* `source` [default= `None` ]: Source of packets. Possible values: `live_interface_name` or  `pcap_file_path`.\n",
    "* `snaplen` [default= `65535` ]: Packet capture length.\n",
    "* `idle_timeout` [default= `30` ]: Flows that are inactive for more than this value in seconds will be exported.\n",
    "* `active_timeout` [default= `300` ]: Flows that are active for more than this value in seconds will be exported.\n",
    "* `plugins` [default= `()` ]: Set of user defined NFPlugins.\n",
    "* `dissect` [default= `True` ]: Enable nDPI deep packet inspection library for Layer 7 visibility.\n",
    "* `max_tcp_dissections` [default= `80` ]: Maximum per flow TCP packets to dissect (ignored when dissect=False).\n",
    "* `max_udp_dissections` [default= `16` ]: Maximum per flow UDP packets to dissect (ignored when dissect=False).\n",
    "* `statistics` [default= `False`]: Enable statistical flow features extraction.\n",
    "* `account_ip_padding_size` [default= `False`]: Enable Ethernet padding accounting when reporting IP sizes.\n",
    "* `enable_guess` [default= True]: Enable/Disable identification engine port guess heuristic.\n",
    "* `decode_tunnels` [default= True]: Enable/Disable GTP/TZSP tunnels dissection.\n",
    "* `bpf_filter` [default= None]: Specify a BPF filter for filtering selected traffic\n",
    "* `promisc` [default= True]: Enable/Disable promiscuous capture mode.\n",
    "\n",
    "`NFStreamer` returns a flow iterator. We can iterate over flows or convert it directly to pandas Dataframe using `to_pandas()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NFStreamer(source=\"pcaps/instagram.pcap\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can enable statistical flow features extraction as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NFStreamer(source=\"pcaps/instagram.pcap\", statistics=True).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can enable IP anonymization as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NFStreamer(source=\"pcaps/instagram.pcap\", statistics=True).to_pandas(ip_anonymization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our Dataframe, we can start analyzing our data as any data. For example we can compute additional features:\n",
    "\n",
    "* Compute data ratio on both direction (src2dst and dst2src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"src2dst_raw_bytes_data_ratio\"] = df['src2dst_raw_bytes'] / df['bidirectional_raw_bytes']\n",
    "df[\"dst2src_raw_bytes_data_ratio\"] = df['dst2src_raw_bytes'] / df['bidirectional_raw_bytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter data according to some criterias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"dst_port\"] == 443].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend nfstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some use cases, we need to add features that are computed as packet level. Thus, nfstream handles such scenario using [**NFPlugin**][nfplugin].\n",
    "\n",
    "[nfplugin]: https://nfstream.github.io/docs/api#nfplugin\n",
    "\n",
    "* Let's suppose that we want bidirectional packets with exact IP size equal to 40 counter per flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class packet_with_40_ip_size(NFPlugin):\n",
    "    def on_init(self, pkt): # flow creation with the first packet\n",
    "        if pkt.ip_size == 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def on_update(self, pkt, flow): # flow update with each packet belonging to the flow\n",
    "        if pkt.ip_size == 40:\n",
    "            flow.packet_with_40_ip_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NFStreamer(source=\"pcaps/google_ssl.pcap\", plugins=[packet_with_40_ip_size()]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataframe have a new column named `packet_with_40_ip_size`.\n",
    "\n",
    "In some cases, we need volatile features.\n",
    "Let's have an example use case as following:\n",
    "\n",
    "* We want to compute the maximum per flow  packet inter arrival time.\n",
    "* Our feature will be based on iat that we do not want as feature.\n",
    "\n",
    "Note that such feature already implemented within nfstream statistical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iat(NFPlugin):\n",
    "    def on_init(self, pkt):\n",
    "        return [-1, pkt.time] # [iat value, last packet timestamp]\n",
    "    def on_update(self, pkt, flow):\n",
    "        flow.iat = [pkt.time - flow.iat[1], pkt.time]\n",
    "\n",
    "class maximum_iat_ms(NFPlugin):\n",
    "    def on_init(self, pkt):\n",
    "        return -1 # we will set it as -1 as init value\n",
    "    def on_update(self, pkt, flow):\n",
    "        if flow.iat[0] > flow.maximum_iat_ms:\n",
    "            flow.maximum_iat_ms = flow.iat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = NFStreamer(source=\"pcaps/instagram.pcap\", plugins=[iat(volatile=True), maximum_iat_ms()]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataframe have a new column named `maximum_iat_ms` containing the maximum observed packet \n",
    "inter arrval time per flow and set to -1 when there is only 1 packet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
